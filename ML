import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

def generate_data():
    np.random.seed(42)
    time_spent = np.random.randint(5, 120, 100)  # Generate random time spent
    premium = (time_spent > 30).astype(int)  # Classify as premium if time_spent > 30 (0 or 1)
    data = pd.DataFrame({'Time Spent': time_spent, 'Premium': premium})
    data.to_csv("synthetic_data.csv", index=False)
    return data

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def compute_cost(X, y, w, b):
    m = X.shape[0]
    z = np.dot(X, w) + b
    h = sigmoid(z)
    cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))
    return cost

def gradient_descent(X, y, w, b, learning_rate, epochs):
    m = X.shape[0]
    for i in range(epochs):
        z = np.dot(X, w) + b
        h = sigmoid(z)
        dw = (1/m) * np.dot(X.T, (h - y))
        db = (1/m) * np.sum(h - y)
        w -= learning_rate * dw
        b -= learning_rate * db
        if i % 100 == 0:
            print(f"Epoch {i}: Cost = {compute_cost(X, y, w, b):.4f}")
    return w, b

def train_logistic_regression():
    data = generate_data()
    X = data[['Time Spent']].values
    y = data['Premium'].values.reshape(-1, 1)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    
    w = np.zeros((X_train.shape[1], 1))
    b = 0
    learning_rate = 0.1
    epochs = 1000
    w, b = gradient_descent(X_train, y_train, w, b, learning_rate, epochs)
    
    predictions = sigmoid(np.dot(X_test, w) + b) >= 0.5
    accuracy = np.mean(predictions == y_test) * 100
    print(f"Test Accuracy: {accuracy:.2f}%")

if _name_ == "_main_":
    train_logistic_regression()
